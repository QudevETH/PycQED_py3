{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples for the use of Iterative Maximum Likelihood Estimation, as well as the pauli_values extraction method, integrated both in analysis_v2 and analysis_v3. The first is an iterative algorithm that reconstructs physical matrices faster than the maximum likelihood algorithm, based on the POVM that we use for tomography measurements. The second one extracts the measured pauli values directly from the data while taking into account the assignment correction done by the calibration points.\n",
    "\n",
    "All results are loaded from Qudev Share, 'Q:\\USERS\\SergiM\\MLE', but can also be found in the respective setup pydata shares using the timestamps. The plots are automatically saved in the data folder; feel free to erase the existing ones to check that each cell generates what you expect (v2 analysis overwrites previous plot even if the method is changed). Everything is backed up.\n",
    "\n",
    "Integration in analysis_v3 is done with results from XLD in the first block, where I also include an example with v2.\n",
    "\n",
    "In the Bluefors1 block, we can find v2 examples on the sets that the method performance was tested with (2qb and 3qb states)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load virtual machine with parameters from XLD, to perform analysis on results from XLD experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pycqedscripts.init.xld.virtual_ATC75_M136_S17HW02_PQSC import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# If running into problems with the initalization, it could be the AWG wave loading lines at the end of the init file.\n",
    "# Commenting out: \n",
    "\n",
    "# for AWG in AWGs:\n",
    "#     pulsar.set(f'{AWG.name}_use_placeholder_waves', True)\n",
    "# pulsar.use_sequence_cache(True)\n",
    "\n",
    "# in lines 1096-1098 (on the last revision in 04/2021) should solve the issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of use in v3 is based on do_state_tomo_analysis function in pycqedscripts.scripts.characterization.state_tomo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import qutip as qtp\n",
    "import collections\n",
    "odict = collections.OrderedDict\n",
    "from pycqed.analysis_v3 import *\n",
    "\n",
    "def do_state_tomo_analysis(timestamp, meas_obj_names=None, rho_target=None,\n",
    "                           estimation_types=None, iterations=None, tolerance=None,\n",
    "                           save_processed_data=True, save_figures=True):\n",
    "    \"\"\"\n",
    "    meas_obj_names: list of qb names. If not provided, will be taken from task_list\n",
    "    \"\"\"\n",
    "    pp = pp_mod.ProcessingPipeline(add_param_method='replace')\n",
    "    try:\n",
    "        if estimation_types is None:\n",
    "            estimation_types=('least_squares', 'max_likelihood')\n",
    "        task_list = hlp_mod.get_param_from_metadata_group(timestamp, 'task_list')\n",
    "        if rho_target is None:\n",
    "            rho_target = qtp.Qobj(task_list[0]['rho_target'])\n",
    "        if meas_obj_names is None:\n",
    "            meas_obj_names = task_list[0]['qubits']\n",
    "        movnm = hlp_mod.get_param_from_metadata_group(timestamp, 'meas_obj_value_names_map')\n",
    "        final_rots_basis = hlp_mod.get_param_from_metadata_group(timestamp, 'final_rots_basis')\n",
    "\n",
    "        params_dict = {}\n",
    "        params_dict.update({f'{qbn}.state_prob_mtx': f'Instrument settings.{qbn}.acq_state_prob_mtx'\n",
    "                            for qbn in meas_obj_names})\n",
    "        pp.add_node('extract_data_hdf', timestamps=timestamp, params_dict=params_dict)\n",
    "        pp.add_node('do_postselection_f_level',\n",
    "                    keys_in='raw',\n",
    "                    num_keys_out=1,\n",
    "                    meas_obj_names=meas_obj_names)\n",
    "        pp.add_node('calculate_flat_multiqubit_shots',\n",
    "                    keys_in='raw',\n",
    "                    joint_processing=True,\n",
    "                    do_preselection=True,\n",
    "                    meas_obj_names=meas_obj_names)\n",
    "        pp.add_node('average_data',\n",
    "                    keys_in='previous calculate_flat_multiqubit_shots',\n",
    "                    averaging_axis=0,\n",
    "                    joint_processing=True,\n",
    "                    meas_obj_names=meas_obj_names)\n",
    "        pp.add_node('correct_readout',\n",
    "                    keys_in='previous average_data',\n",
    "                    joint_processing=True,\n",
    "                    meas_obj_names=meas_obj_names)\n",
    "        pp.add_node('extract_leakage_classified_shots',\n",
    "                    keys_in='previous correct_readout',\n",
    "                    joint_processing=True,\n",
    "                    meas_obj_names=meas_obj_names)\n",
    "        pp.add_node('state_tomography_analysis',\n",
    "                    keys_in='previous do_postselection_f_level',\n",
    "                    meas_obj_names=meas_obj_names,\n",
    "                    keys_in_leakage=['previous extract_leakage_classified_shots'],\n",
    "                    joint_processing=True,\n",
    "                    basis_rots=final_rots_basis,\n",
    "                    do_preselection=True,\n",
    "                    rho_target=rho_target,\n",
    "                    iterations=iterations,\n",
    "                    tolerance=tolerance,\n",
    "                    estimation_types=estimation_types)\n",
    "\n",
    "        pp.resolve(movnm)\n",
    "        pp()\n",
    "        pp.save(save_processed_data=save_processed_data, save_figures=save_figures)\n",
    "        return pp\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        return pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load two experiment results for v2 and v3 test respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp = '20210131_201258' \n",
    "\n",
    "a_tools.datadir = r'Q:\\USERS\\SergiM\\MLE'\n",
    "MC.datadir(r'Q:\\USERS\\SergiM\\MLE')\n",
    "\n",
    "for qb in qubits:\n",
    "    gen.load_settings(qb, timestamp=timestamp)\n",
    "gen.load_settings(dev, timestamp=timestamp)\n",
    "\n",
    "ts_start = '20210131_201258' \n",
    "ts_end = '20210131_222513' \n",
    "\n",
    "timestamps_v3 = a_tools.get_timestamps_in_range(ts_start, ts_end)\n",
    "print(timestamps_v3)\n",
    "\n",
    "rho_phi = qtp.Qobj([[1/2,0,0,1/2],[0,0,0,0],[0,0,0,0],[1/2,0,0,1/2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis_v3 example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New method is called 'iterative_mle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_state_tomo_analysis(timestamps_v3[1], rho_target=rho_phi, estimation_types=['iterative_mle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set manually the maximum iterations and the minimum tolerance for change between consecutive steps. In this example the limit will be set by iterations before the tolerance is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_state_tomo_analysis(timestamps_v3[1], rho_target=rho_phi, estimation_types=['iterative_mle'], iterations=100, tolerance=-18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing, a good default value for tolerance seemed -15 for 2 qubits and -18 for 3 qubits. Iterations are set to 1000 by default to give preference to tolerance limits; -18 tolerance corresponds to iterations on the order of 100 on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract pauli values directly, we can use 'pauli_values'. This method does not reconstruct physical matrices, like LST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_state_tomo_analysis(timestamps_v3[1], rho_target=rho_phi, estimation_types=['pauli_values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis_v2 example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With v2 we need to load more information into the analysis function. This can be found in the experiment hdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rots_basis=('I', 'X180', 'Y90', 'mY90', 'X90', 'mX90')\n",
    "use_cal_points = True\n",
    "preselection = True\n",
    "qbs = (qb10, qb9)\n",
    "measure_qubits = [qb10,qb9]\n",
    "num_qubits = len(measure_qubits)\n",
    "meas_obj_names = ['qb10','qb9']\n",
    "thresholds = {qb.name: qb.acq_classifier_params()['thresholds'][0] for qb in measure_qubits}\n",
    "for qb in measure_qubits:\n",
    "    qb.update_detector_functions()\n",
    "channel_map = {qb.name: qb.int_log_det.value_names[0] + f' {qb.instr_uhf()}' for qb in measure_qubits}\n",
    "n_segments = len(rots_basis)**num_qubits + (2**num_qubits if use_cal_points else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike v3, the method is specified with a keyworded parameter 'name_of_method'=True. The hierarchy of preference in the methods is 'pauli_values' > 'pauli_raw'* > 'imle' > 'mle'; this order is also specified in the code.\n",
    "\n",
    "*older method for direct pauli extraction without assignment correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = timestamps_v3[0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "MA = tda.StateTomographyAnalysis(t_start=ts, options_dict=dict(\n",
    "    n_readouts=(2 if preselection else 1)*n_segments,\n",
    "    thresholds=odict([(qb.name, thresholds[qb.name]) for qb in qbs]),\n",
    "    channel_map=odict([(qb.name, channel_map[qb.name]) for qb in qbs]),\n",
    "    cal_points=[odict([(channel_map[qb.name], [2*i+1 if preselection else i]) \n",
    "                       for qb in measure_qubits]) for i in np.arange(-2**num_qubits, 0)],\n",
    "    data_type='singleshot',\n",
    "    rho_target=rho_phi,\n",
    "    basis_rots_str=rots_basis,\n",
    "    covar_matrix=np.diag(np.ones(2**num_qubits)),\n",
    "    imle=True,\n",
    "    use_preselection=preselection,\n",
    "    data_filter=(lambda data: data[1:2*len(rots_basis)**num_qubits+1:2]) if preselection \\\n",
    "        else (lambda data: data[:len(rots_basis)**num_qubits])\n",
    "))\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = timestamps_v3[0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "MA = tda.StateTomographyAnalysis(t_start=ts, options_dict=dict(\n",
    "    n_readouts=(2 if preselection else 1)*n_segments,\n",
    "    thresholds=odict([(qb.name, thresholds[qb.name]) for qb in qbs]),\n",
    "    channel_map=odict([(qb.name, channel_map[qb.name]) for qb in qbs]),\n",
    "    cal_points=[odict([(channel_map[qb.name], [2*i+1 if preselection else i]) \n",
    "                       for qb in measure_qubits]) for i in np.arange(-2**num_qubits, 0)],\n",
    "    data_type='singleshot',\n",
    "    rho_target=rho_phi,\n",
    "    basis_rots_str=rots_basis,\n",
    "    covar_matrix=np.diag(np.ones(2**num_qubits)),\n",
    "    pauli_values=True,\n",
    "    use_preselection=preselection,\n",
    "    data_filter=(lambda data: data[1:2*len(rots_basis)**num_qubits+1:2]) if preselection \\\n",
    "        else (lambda data: data[:len(rots_basis)**num_qubits])\n",
    "))\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bluefors1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load virtual machine with parameters from Bluefors1, to perform analysis on results from BF1 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycqedscripts.init.bluefors1.ATC81_M138_S705_test import *\n",
    "\n",
    "init_dict = initialize_setup(virtual_setup=True)\n",
    "globals().update(**init_dict)\n",
    "clear_output()\n",
    "\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "startup = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on 2 qubits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 6 bell state tomographies on different qubit pairs of a BF1 chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_tools.datadir = r'Q:\\USERS\\SergiM\\MLE'\n",
    "MC.datadir(r'Q:\\USERS\\SergiM\\MLE')\n",
    "\n",
    "ts_start = '20210210_140836' \n",
    "ts_end = '20210210_142102' \n",
    "\n",
    "timestamps = a_tools.get_timestamps_in_range(ts_start, ts_end)\n",
    "    \n",
    "for qb in qubits:\n",
    "    gen.load_settings(qb, timestamp=timestamps[0])\n",
    "if startup:\n",
    "    dev.add_2qb_gate('CZ_nztc', 'NZTransitionControlledPulse')\n",
    "    startup = False\n",
    "gen.load_settings(dev, timestamp=timestamps[0])\n",
    "\n",
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load parameters needed for v2 analysis. These can be found and extracted from the hdf measurement file if they are not known. I also define the target state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rots_basis=('I', 'X180', 'Y90', 'mY90', 'X90', 'mX90')\n",
    "use_cal_points = True\n",
    "preselection = False\n",
    "qbs_list = [(qb3, qb1),(qb3, qb6),(qb4, qb1),(qb4, qb7),(qb5, qb2),(qb5, qb7)]\n",
    "measure_qubits_list = [[qb3, qb1],[qb3, qb6],[qb4, qb1],[qb4, qb7],[qb5, qb2],[qb5, qb7]]\n",
    "num_qubits = 2\n",
    "\n",
    "thresholds = {qb.name: qb.acq_classifier_params()['thresholds'][0] for qb in qubits}\n",
    "for qb in qubits:\n",
    "    qb.update_detector_functions()\n",
    "channel_map = {qb.name: qb.int_log_det.value_names[0] + f' {qb.instr_uhf()}' for qb in qubits}\n",
    "n_segments = len(rots_basis)**2 + (2**2 if use_cal_points else 0)\n",
    "\n",
    "rho_phi = qtp.Qobj([[1/2,0,0,1/2],[0,0,0,0],[0,0,0,0],[1/2,0,0,1/2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples with IMLE method on n of the 6 loaded examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ts in enumerate(timestamps[:n]):\n",
    "    print(i)\n",
    "    measure_qubits = measure_qubits_list[i]\n",
    "    qbs = qbs_list[i]\n",
    "    rho_target = rho_phi\n",
    "    \n",
    "    start_time = time.time()\n",
    "    num_qubits = len(measure_qubits)\n",
    "\n",
    "    MA = tda.StateTomographyAnalysis(t_start=ts, options_dict=dict(\n",
    "        n_readouts=(2 if preselection else 1)*n_segments,\n",
    "        thresholds=odict([(qb.name, thresholds[qb.name]) for qb in qbs]),\n",
    "        channel_map=odict([(qb.name, channel_map[qb.name]) for qb in qbs]),\n",
    "        cal_points=[odict([(channel_map[qb.name], [2*i+1 if preselection else i]) \n",
    "                           for qb in measure_qubits]) for i in np.arange(-2**num_qubits, 0)],\n",
    "        data_type='singleshot',\n",
    "        rho_target=rho_target,\n",
    "        basis_rots_str=rots_basis,\n",
    "        imle = True,\n",
    "        covar_matrix=np.diag(np.ones(2**num_qubits)),\n",
    "        use_preselection=preselection,\n",
    "        data_filter=(lambda data: data[1:2*len(rots_basis)**num_qubits+1:2]) if preselection \\\n",
    "            else (lambda data: data[:len(rots_basis)**num_qubits])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set arbitrary tolerance and iteration limits like this (Effect and default values are explained in the XLD block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ts in enumerate(timestamps[:n]):\n",
    "    print(i)\n",
    "    measure_qubits = measure_qubits_list[i]\n",
    "    qbs = qbs_list[i]\n",
    "    rho_target = rho_phi\n",
    "    \n",
    "    start_time = time.time()\n",
    "    num_qubits = len(measure_qubits)\n",
    "\n",
    "    MA = tda.StateTomographyAnalysis(t_start=ts, options_dict=dict(\n",
    "        n_readouts=(2 if preselection else 1)*n_segments,\n",
    "        thresholds=odict([(qb.name, thresholds[qb.name]) for qb in qbs]),\n",
    "        channel_map=odict([(qb.name, channel_map[qb.name]) for qb in qbs]),\n",
    "        cal_points=[odict([(channel_map[qb.name], [2*i+1 if preselection else i]) \n",
    "                           for qb in measure_qubits]) for i in np.arange(-2**num_qubits, 0)],\n",
    "        data_type='singleshot',\n",
    "        rho_target=rho_target,\n",
    "        basis_rots_str=rots_basis,\n",
    "        imle = True,\n",
    "        iterations = 100,\n",
    "        tolerance = -18,\n",
    "        covar_matrix=np.diag(np.ones(2**num_qubits)),\n",
    "        use_preselection=preselection,\n",
    "        data_filter=(lambda data: data[1:2*len(rots_basis)**num_qubits+1:2]) if preselection \\\n",
    "            else (lambda data: data[:len(rots_basis)**num_qubits])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples with pauli_values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ts in enumerate(timestamps[:n]):\n",
    "    print(i)\n",
    "    measure_qubits = measure_qubits_list[i]\n",
    "    qbs = qbs_list[i]\n",
    "    rho_target = rho_phi\n",
    "    \n",
    "    start_time = time.time()\n",
    "    num_qubits = len(measure_qubits)\n",
    "\n",
    "    MA = tda.StateTomographyAnalysis(t_start=ts, options_dict=dict(\n",
    "        n_readouts=(2 if preselection else 1)*n_segments,\n",
    "        thresholds=odict([(qb.name, thresholds[qb.name]) for qb in qbs]),\n",
    "        channel_map=odict([(qb.name, channel_map[qb.name]) for qb in qbs]),\n",
    "        cal_points=[odict([(channel_map[qb.name], [2*i+1 if preselection else i]) \n",
    "                           for qb in measure_qubits]) for i in np.arange(-2**num_qubits, 0)],\n",
    "        data_type='singleshot',\n",
    "        rho_target=rho_target,\n",
    "        basis_rots_str=rots_basis,\n",
    "        pauli_values = True,\n",
    "        covar_matrix=np.diag(np.ones(2**num_qubits)),\n",
    "        use_preselection=preselection,\n",
    "        data_filter=(lambda data: data[1:2*len(rots_basis)**num_qubits+1:2]) if preselection \\\n",
    "            else (lambda data: data[:len(rots_basis)**num_qubits])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on 3 qubits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 9 data sets for tomographies of 3-qubit states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp = '20201208_140754' \n",
    "\n",
    "a_tools.datadir = r'Q:\\USERS\\SergiM\\MLE'\n",
    "MC.datadir(r'Q:\\USERS\\SergiM\\MLE')\n",
    "\n",
    "for qb in qubits:\n",
    "    gen.load_settings(qb, timestamp=timestamp)\n",
    "\n",
    "cz_type = 'CZ_nztc'\n",
    "if startup:\n",
    "    dev.add_2qb_gate('CZ_nztc', 'NZTransitionControlledPulse')\n",
    "    startup = False\n",
    "gen.load_settings(dev, timestamp=timestamp)\n",
    "\n",
    "ts_start = '20201208_140754' \n",
    "ts_end = '20201208_144607' \n",
    "\n",
    "timestamps = a_tools.get_timestamps_in_range(ts_start, ts_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load parameters needed for v2 analysis. These can be found and extracted from the hdf measurement file if they are not known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rots_basis=('I', 'X180', 'Y90', 'mY90', 'X90', 'mX90')\n",
    "use_cal_points = True\n",
    "preselection = True\n",
    "qbs = (qb1, qb3, qb6)\n",
    "measure_qubits = [qb1, qb3, qb6]\n",
    "num_qubits = len(measure_qubits)\n",
    "meas_obj_names = ['qb1','qb3','qb6']\n",
    "thresholds = {qb.name: qb.acq_classifier_params()['thresholds'][0] for qb in measure_qubits}\n",
    "for qb in measure_qubits:\n",
    "    qb.update_detector_functions()\n",
    "channel_map = {qb.name: qb.int_log_det.value_names[0] + f' {qb.instr_uhf()}' for qb in measure_qubits}\n",
    "n_segments = len(rots_basis)**3 + (2**3 if use_cal_points else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads the prepared states from the experiment files, which correspond to some ground states of a quantum phase recognition experiment and are not trivial to write like the 2 qb Bell state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_preparation(num_qubits,param_set):\n",
    "\n",
    "    g_st = qtp.basis(2,0)\n",
    "    if num_qubits == 3:\n",
    "        initial = qtp.tensor(g_st,g_st,g_st)\n",
    "        rot1 = qtp.tensor(qtp.qip.operations.ry(param_set[0]),qtp.qip.operations.ry(param_set[1]),qtp.qeye(2))\n",
    "        cz1 = qtp.tensor(qtp.qip.operations.csign(),qtp.qeye(2))\n",
    "        rot2 = qtp.tensor(qtp.qip.operations.ry(param_set[2]), qtp.qip.operations.ry(param_set[3]), qtp.qip.operations.ry(param_set[4]))\n",
    "        cz2 = qtp.tensor(qtp.qeye(2),qtp.qip.operations.csign())\n",
    "        rot3 = qtp.tensor(qtp.qeye(2), qtp.qip.operations.ry(param_set[5]), qtp.qip.operations.ry(param_set[6]))\n",
    "    elif num_qubits == 7:\n",
    "        initial = qtp.tensor(g_st,g_st,g_st,g_st,g_st,g_st,g_st)\n",
    "        rot1 = qtp.tensor(qtp.ry(param_set[0]),qtp.ry(param_set[1]),qtp.ry(param_set[2]),qtp.ry(param_set[3]),qtp.ry(param_set[4]),qtp.ry(param_set[5]),qeye(2))\n",
    "        cz1 = qtp.tensor(qtp.csign(),qtp.csign(),qtp.csign(),qtp.qeye(2))\n",
    "        rot2 = qtp.tensor(qtp.ry(param_set[6]),qtp.ry(param_set[7]),qtp.ry(param_set[8]),qtp.ry(param_set[9]),qtp.ry(param_set[10]),qtp.ry(param_set[11]),qtp.ry(param_set[12]))\n",
    "        cz2 = qtp.tensor(qtp.qeye(2),qtp.csign(),qtp.csign(),qtp.csign())\n",
    "        rot3 = qtp.tensor(qtp.qeye(2),qtp.ry(param_set[13]),qtp.ry(param_set[14]),qtp.ry(param_set[15]),qtp.ry(param_set[16]),qtp.ry(param_set[17]),qtp.ry(param_set[18]))\n",
    "\n",
    "    psi_target = rot3 * cz2 * rot2 * cz1 * rot1 * initial\n",
    "\n",
    "    rho_target = (psi_target * psi_target.dag()).full()\n",
    "    \n",
    "    return rho_target\n",
    "\n",
    "# Read the generated states from the csv files\n",
    "param_set = []\n",
    "rho_target_list = []\n",
    "try:\n",
    "    for ts in timestamps:\n",
    "        read_data = []\n",
    "        with open(a_tools.data_from_time(ts) + \"\\\\OptParams.csv\") as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count = 0\n",
    "            for row in csv_reader:\n",
    "                read_data.append(row)\n",
    "            param = [float(var) for var in read_data[0]]\n",
    "        param_set.append(param)\n",
    "        exp_target = qtp.Qobj(state_preparation(num_qubits, param), dims=[[2,2,2],[2,2,2]])\n",
    "        rho_target_list.append(exp_target)\n",
    "except FileNotFoundError:\n",
    "    print('file not found. Using default rho comparison')\n",
    "    J = 1.0\n",
    "    h2_list = np.linspace(-1.6, 1.6, 9)\n",
    "    h1_list = [0.1]\n",
    "\n",
    "    fid_list = []\n",
    "    rho_target_list = []\n",
    "    exp_list = []\n",
    "    i=0\n",
    "    for h1 in h1_list:\n",
    "        for h2 in h2_list:\n",
    "            # Target ground state\n",
    "            psi_target = H_qpr_s(J, h1, h2).groundstate()[1]\n",
    "            rho_target = psi_target * psi_target.dag()\n",
    "            rho_target_list.append(rho_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imle and pauli tests on n of the 9 states of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j, ts in enumerate(timestamps[:n]):\n",
    "    print(j)\n",
    "    start_time = time.time()\n",
    "\n",
    "    rho_target = rho_target_list[j]\n",
    "\n",
    "    MA = tda.StateTomographyAnalysis(t_start=ts, options_dict=dict(\n",
    "        n_readouts=(2 if preselection else 1)*n_segments,\n",
    "        thresholds=odict([(qb.name, thresholds[qb.name]) for qb in qbs]),\n",
    "        channel_map=odict([(qb.name, channel_map[qb.name]) for qb in qbs]),\n",
    "        cal_points=[odict([(channel_map[qb.name], [2*i+1 if preselection else i]) \n",
    "                           for qb in measure_qubits]) for i in np.arange(-2**num_qubits, 0)],\n",
    "        data_type='singleshot',\n",
    "        rho_target=rho_target,\n",
    "        basis_rots_str=rots_basis,\n",
    "        covar_matrix=np.diag(np.ones(2**num_qubits)),\n",
    "        imle=True,\n",
    "        use_preselection=preselection,\n",
    "        data_filter=(lambda data: data[1:2*len(rots_basis)**num_qubits+1:2]) if preselection \\\n",
    "            else (lambda data: data[:len(rots_basis)**num_qubits])\n",
    "    ))\n",
    "    print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, ts in enumerate(timestamps[:1]):\n",
    "    print(j)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    num_qubits = 3\n",
    "    rho_target = rho_target_list[j]\n",
    "\n",
    "    MA = tda.StateTomographyAnalysis(t_start=ts, options_dict=dict(\n",
    "        n_readouts=(2 if preselection else 1)*n_segments,\n",
    "        thresholds=odict([(qb.name, thresholds[qb.name]) for qb in qbs]),\n",
    "        channel_map=odict([(qb.name, channel_map[qb.name]) for qb in qbs]),\n",
    "        cal_points=[odict([(channel_map[qb.name], [2*i+1 if preselection else i]) \n",
    "                           for qb in measure_qubits]) for i in np.arange(-2**num_qubits, 0)],\n",
    "        data_type='singleshot',\n",
    "        rho_target=rho_target,\n",
    "        basis_rots_str=rots_basis,\n",
    "        covar_matrix=np.diag(np.ones(2**num_qubits)),\n",
    "        pauli_values=True,\n",
    "        use_preselection=preselection,\n",
    "        data_filter=(lambda data: data[1:2*len(rots_basis)**num_qubits+1:2]) if preselection \\\n",
    "            else (lambda data: data[:len(rots_basis)**num_qubits])\n",
    "    ))\n",
    "    print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set arbitrary iterations and tolerance for the method following the example with 2 qubits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
